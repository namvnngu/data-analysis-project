{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The summary of data cleaning:\n",
    "1. Find and correct errors in nominal data\n",
    "2. Find and count the total number of missing values (nan/null) for each column\n",
    "3. Drop columns with more than 10% missing values\n",
    "4. Drop rows with more than 20% missing values\n",
    "5. Calculate z-score for columns with continuous data and replace outliers by the mean\n",
    "6. Replace all missing values by implementing appropriate algorithms such as Linear Regression or the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "import collections\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n",
      "       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
      "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
      "       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n",
      "       'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RISK_MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>141556.000000</td>\n",
       "      <td>141871.000000</td>\n",
       "      <td>140787.000000</td>\n",
       "      <td>81350.000000</td>\n",
       "      <td>74377.000000</td>\n",
       "      <td>132923.000000</td>\n",
       "      <td>140845.000000</td>\n",
       "      <td>139563.000000</td>\n",
       "      <td>140419.000000</td>\n",
       "      <td>138583.000000</td>\n",
       "      <td>128179.000000</td>\n",
       "      <td>128212.000000</td>\n",
       "      <td>88536.000000</td>\n",
       "      <td>85099.000000</td>\n",
       "      <td>141289.000000</td>\n",
       "      <td>139467.000000</td>\n",
       "      <td>142193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.186400</td>\n",
       "      <td>23.226784</td>\n",
       "      <td>2.349974</td>\n",
       "      <td>5.469824</td>\n",
       "      <td>7.624853</td>\n",
       "      <td>39.984292</td>\n",
       "      <td>14.001988</td>\n",
       "      <td>18.637576</td>\n",
       "      <td>68.843810</td>\n",
       "      <td>51.482606</td>\n",
       "      <td>1017.653758</td>\n",
       "      <td>1015.258204</td>\n",
       "      <td>4.437189</td>\n",
       "      <td>4.503167</td>\n",
       "      <td>16.987509</td>\n",
       "      <td>21.687235</td>\n",
       "      <td>2.360682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.403283</td>\n",
       "      <td>7.117618</td>\n",
       "      <td>8.465173</td>\n",
       "      <td>4.188537</td>\n",
       "      <td>3.781525</td>\n",
       "      <td>13.588801</td>\n",
       "      <td>8.893337</td>\n",
       "      <td>8.803345</td>\n",
       "      <td>19.051293</td>\n",
       "      <td>20.797772</td>\n",
       "      <td>7.105476</td>\n",
       "      <td>7.036677</td>\n",
       "      <td>2.887016</td>\n",
       "      <td>2.720633</td>\n",
       "      <td>6.492838</td>\n",
       "      <td>6.937594</td>\n",
       "      <td>8.477969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.500000</td>\n",
       "      <td>-4.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>980.500000</td>\n",
       "      <td>977.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.200000</td>\n",
       "      <td>-5.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.600000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1012.900000</td>\n",
       "      <td>1010.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1017.600000</td>\n",
       "      <td>1015.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.800000</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1022.400000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1041.000000</td>\n",
       "      <td>1039.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>46.700000</td>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MinTemp        MaxTemp       Rainfall   Evaporation  \\\n",
       "count  141556.000000  141871.000000  140787.000000  81350.000000   \n",
       "mean       12.186400      23.226784       2.349974      5.469824   \n",
       "std         6.403283       7.117618       8.465173      4.188537   \n",
       "min        -8.500000      -4.800000       0.000000      0.000000   \n",
       "25%         7.600000      17.900000       0.000000      2.600000   \n",
       "50%        12.000000      22.600000       0.000000      4.800000   \n",
       "75%        16.800000      28.200000       0.800000      7.400000   \n",
       "max        33.900000      48.100000     371.000000    145.000000   \n",
       "\n",
       "           Sunshine  WindGustSpeed   WindSpeed9am   WindSpeed3pm  \\\n",
       "count  74377.000000  132923.000000  140845.000000  139563.000000   \n",
       "mean       7.624853      39.984292      14.001988      18.637576   \n",
       "std        3.781525      13.588801       8.893337       8.803345   \n",
       "min        0.000000       6.000000       0.000000       0.000000   \n",
       "25%        4.900000      31.000000       7.000000      13.000000   \n",
       "50%        8.500000      39.000000      13.000000      19.000000   \n",
       "75%       10.600000      48.000000      19.000000      24.000000   \n",
       "max       14.500000     135.000000     130.000000      87.000000   \n",
       "\n",
       "         Humidity9am    Humidity3pm    Pressure9am    Pressure3pm  \\\n",
       "count  140419.000000  138583.000000  128179.000000  128212.000000   \n",
       "mean       68.843810      51.482606    1017.653758    1015.258204   \n",
       "std        19.051293      20.797772       7.105476       7.036677   \n",
       "min         0.000000       0.000000     980.500000     977.100000   \n",
       "25%        57.000000      37.000000    1012.900000    1010.400000   \n",
       "50%        70.000000      52.000000    1017.600000    1015.200000   \n",
       "75%        83.000000      66.000000    1022.400000    1020.000000   \n",
       "max       100.000000     100.000000    1041.000000    1039.600000   \n",
       "\n",
       "           Cloud9am      Cloud3pm        Temp9am        Temp3pm        RISK_MM  \n",
       "count  88536.000000  85099.000000  141289.000000  139467.000000  142193.000000  \n",
       "mean       4.437189      4.503167      16.987509      21.687235       2.360682  \n",
       "std        2.887016      2.720633       6.492838       6.937594       8.477969  \n",
       "min        0.000000      0.000000      -7.200000      -5.400000       0.000000  \n",
       "25%        1.000000      2.000000      12.300000      16.600000       0.000000  \n",
       "50%        5.000000      5.000000      16.700000      21.100000       0.000000  \n",
       "75%        7.000000      7.000000      21.600000      26.400000       0.800000  \n",
       "max        9.000000      9.000000      40.200000      46.700000     371.000000  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve data\n",
    "data = pd.read_csv('data/weatherAUS.csv')\n",
    "columns = data.columns\n",
    "print(columns)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: The date of observation\n",
      "\n",
      "Location: The common name of the location of the weather station\n",
      "\n",
      "MinTemp: The minimum temperature in degrees celsius\n",
      "\n",
      "MaxTemp: The maximum temperature in degrees celsius\n",
      "\n",
      "Rainfall: The amount of rainfall recorded for the day in mm\n",
      "\n",
      "Evaporation: The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
      "\n",
      "Sunshine: The number of hours of bright sunshine in the day\n",
      "\n",
      "WindGustDir: The direction of the strongest wind gust in the 24 hours to midnight\n",
      "\n",
      "WindGustSpeed: The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
      "\n",
      "WindDir9am: Direction of the wind at 9am\n",
      "\n",
      "WindDir3pm: Direction of the wind at 3pm\n",
      "\n",
      "WindSpeed9am: Wind speed (km/hr) averaged over 10 minutes prior to 9am\n",
      "\n",
      "WindSpeed3pm: Wind speed (km/hr) averaged over 10 minutes prior to 3pm\n",
      "\n",
      "Humidity9am: Humidity (percent) at 9am\n",
      "\n",
      "Humidity3pm: Humidity (percent) at 3pm\n",
      "\n",
      "Pressure9am: Atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
      "\n",
      "Pressure3pm: Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
      "\n",
      "Cloud9am: Fraction of sky obscured by cloud at 9am. This is measured in 'oktas', which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast.\n",
      "\n",
      "Cloud3pm: Fraction of sky obscured by cloud (in 'oktas': eighths) at 3pm. See Cload9am for a description of the values\n",
      "\n",
      "Temp9am: Temperature (degrees C) at 9am\n",
      "\n",
      "Temp3pm: Temperature (degrees C) at 3pm\n",
      "\n",
      "RainToday: Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n",
      "\n",
      "RISK_MM: The amount of next day rain in mm. Used to create response variable RainTomorrow. A kind of measure of the 'risk'.\n",
      "\n",
      "RainTomorrow: The target variable. Did it rain tomorrow?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data information\n",
    "with open('data/data_info.json', 'r') as fp:\n",
    "    data_info = json.load(fp)\n",
    "\n",
    "for key, value in data_info.items():\n",
    "    print(f'{key}: {value}')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find and correct errors in nominal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nominal columns: Date, Location, WindGustDir, WindDir9am, WindDir3pm, RainToday, RainTomorrow\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find nominal columns by searching non-float columns\n",
    "\"\"\"\n",
    "\n",
    "string_columns = []\n",
    "float_columns = []\n",
    "data_types = data.dtypes.values\n",
    "\n",
    "for index in range(len(data_types)):\n",
    "    if data_types[index] != np.dtype('float64'):\n",
    "        string_columns.append(index)\n",
    "    else:\n",
    "        float_columns.append(index) # z-score\n",
    "        \n",
    "continous_columns = [columns[col] for col in float_columns]   # z-score   \n",
    "nominal_columns = [columns[col] for col in string_columns]\n",
    "print(\"The nominal columns:\", \", \".join(nominal_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no invalid date in 'Date' column in terms of format.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluate Date\n",
    "\"\"\"\n",
    "# Define a function to check if the date is valid\n",
    "def check_valid_format(date):\n",
    "    date_format = '%Y-%m-%d'\n",
    "    try:\n",
    "        datetime.datetime.strptime(date, date_format)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "# In order to reduce iteration time, find all unique dates\n",
    "unique_date = set(data[nominal_columns[0]])\n",
    "\n",
    "# An array of boolean values: True if value; otherwise, False\n",
    "is_valid_date_format = []\n",
    "for date in unique_date:\n",
    "    is_valid_date_format.append(check_valid_format(date))\n",
    "    \n",
    "# Find invalid data corresponding to False\n",
    "count = 0\n",
    "invalid_date = []\n",
    "for index in range(len(is_valid_date_format)):\n",
    "    if is_valid_date_format[index] == False:\n",
    "        count += 1\n",
    "        invalid_date.append(is_vaid_date_format[index])\n",
    "        \n",
    "if count == 0:\n",
    "    print(\"There are no invalid date in 'Date' column in terms of format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Before fixed: CoffsHarbour, Newcastle, Woomera, Ballarat, Adelaide, NorahHead, Penrith, Brisbane, PerthAirport, Witchcliffe, Dartmoor, Wollongong, NorfolkIsland, Richmond, AliceSprings, Katherine, Canberra, MountGambier, WaggaWagga, Cobar, Albury, Albany, Williamtown, Sale, GoldCoast, Launceston, Sydney, Moree, SalmonGums, Nuriootpa, BadgerysCreek, MountGinini, Bendigo, Nhil, MelbourneAirport, Townsville, PearceRAAF, Watsonia, Perth, Walpole, Mildura, Darwin, Melbourne, Portland, Hobart, SydneyAirport, Cairns, Uluru, Tuggeranong\n",
      "\n",
      "***After fixed: Coffs Harbour, Newcastle, Woomera, Ballarat, Adelaide, Norah Head, Penrith, Brisbane, Perth Airport, Witchcliffe, Dartmoor, Wollongong, Norfolk Island, Richmond, Alice Springs, Katherine, Canberra, Mount Gambier, Wagga Wagga, Cobar, Albury, Albany, Williamtown, Sale, Gold Coast, Launceston, Sydney, Moree, Salmon Gums, Nuriootpa, Badgerys Creek, Mount Ginini, Bendigo, Nhil, Melbourne Airport, Townsville, Pearce RA AF, Watsonia, Perth, Walpole, Mildura, Darwin, Melbourne, Portland, Hobart, Sydney Airport, Cairns, Uluru, Tuggeranong\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluate Location\n",
    "\"\"\"\n",
    "# In order to reduce iteration time, find all unique location\n",
    "unique_location = set(data[nominal_columns[1]])\n",
    "print(\"***Before fixed:\", \", \".join(unique_location))\n",
    "print(\"\")\n",
    "\n",
    "# There are some locations needed to be fixed\n",
    "# Insert a space before capitcal letter if the location\n",
    "# name has 2 words\n",
    "fixed_location = []\n",
    "for location in unique_location:\n",
    "    fixed_name = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", location)\n",
    "    fixed_location.append(fixed_name)\n",
    "\n",
    "print(\"***After fixed:\",\", \".join(fixed_location))\n",
    "\n",
    "# Replace the old locations with the fixed locations\n",
    "data = data.replace(unique_location, fixed_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The direction: SW, NNE, SSE, SE, E, W, N, NW, WNW, SSW, NE, NNW, WSW, S, ENE, ESE\n",
      "There is no invalid data in WinGusGir column in terms of format.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "WindGustDir\n",
    "\"\"\"\n",
    "# In order to reduce iteration time, find all unique WindGustDir\n",
    "unique_WindGustDir = list(set(data[nominal_columns[2]]))\n",
    "unique_WindGustDir.remove(np.nan)\n",
    "print(\"The direction:\", \", \".join(unique_WindGustDir))\n",
    "\n",
    "print(\"There is no invalid data in WinGusGir column in terms of format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The direction: SW, SSE, NNE, SE, SSW, W, N, E, NW, WNW, NE, NNW, WSW, S, ENE, ESE\n",
      "There is no invalid data in WindDir9am column in terms of format.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "WindDir9am\n",
    "\"\"\"\n",
    "# In order to reduce iteration time, find all unique WindDir9am\n",
    "unique_WindDir9am = list(set(data[nominal_columns[3]]))\n",
    "unique_WindDir9am.remove(np.nan)\n",
    "print(\"The direction:\", \", \".join(unique_WindDir9am))\n",
    "\n",
    "print(\"There is no invalid data in WindDir9am column in terms of format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The direction: SW, SSE, NNE, SE, SSW, W, N, E, NW, WNW, NE, NNW, WSW, S, ENE, ESE\n",
      "There is no invalid data in WindDir3pm cloumn in terms of format.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "WindDir3pm\n",
    "\"\"\"\n",
    "# In order to reduce iteration time, find all unique WindDir3pm\n",
    "unique_WindDir3pm = list(set(data[nominal_columns[4]]))\n",
    "unique_WindDir3pm.remove(np.nan)\n",
    "print(\"The direction:\", \", \".join(unique_WindDir9am))\n",
    "\n",
    "print(\"There is no invalid data in WindDir3pm cloumn in terms of format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values: Yes, No\n",
      "There is no invalid data in RainToday cloumn in terms of grammar.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RainToday\n",
    "\"\"\"\n",
    "# In order to reduce iteration time, find all unique RainToday\n",
    "unique_RainToday = list(set(data[nominal_columns[5]]))\n",
    "unique_RainToday.remove(np.nan)\n",
    "print(\"The values:\", \", \".join(unique_RainToday))\n",
    "\n",
    "print(\"There is no invalid data in RainToday cloumn in terms of grammar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values: Yes, No\n",
      "There is no invalid data in RainTomorrow cloumn in terms of grammar.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RainTomorrow\n",
    "\"\"\"\n",
    "# In order to reduce iteration time, find all unique RainTomorrow\n",
    "unique_RainTomorrow = list(set(data[nominal_columns[6]]))\n",
    "print(\"The values:\", \", \".join(unique_RainTomorrow))\n",
    "\n",
    "print(\"There is no invalid data in RainTomorrow cloumn in terms of grammar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find and count the total number of missing values (nan/null) for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no nan values in Date.\n",
      "There are no nan values in Location.\n",
      "The number of nan value in MinTemp: 637\n",
      "The number of nan value in MaxTemp: 322\n",
      "The number of nan value in Rainfall: 1406\n",
      "The number of nan value in Evaporation: 60843\n",
      "The number of nan value in Sunshine: 67816\n",
      "The number of nan value in WindGustDir: 9330\n",
      "The number of nan value in WindGustSpeed: 9270\n",
      "The number of nan value in WindDir9am: 10013\n",
      "The number of nan value in WindDir3pm: 3778\n",
      "The number of nan value in WindSpeed9am: 1348\n",
      "The number of nan value in WindSpeed3pm: 2630\n",
      "The number of nan value in Humidity9am: 1774\n",
      "The number of nan value in Humidity3pm: 3610\n",
      "The number of nan value in Pressure9am: 14014\n",
      "The number of nan value in Pressure3pm: 13981\n",
      "The number of nan value in Cloud9am: 53657\n",
      "The number of nan value in Cloud3pm: 57094\n",
      "The number of nan value in Temp9am: 904\n",
      "The number of nan value in Temp3pm: 2726\n",
      "The number of nan value in RainToday: 1406\n",
      "There are no nan values in RISK_MM.\n",
      "There are no nan values in RainTomorrow.\n"
     ]
    }
   ],
   "source": [
    "def count_nan(column, data):\n",
    "    count = int(data[column].isna().sum())\n",
    "    return count\n",
    "\n",
    "def print_index(count, column):\n",
    "    if count == 0:\n",
    "        print(f\"There are no nan values in {column}.\")\n",
    "    else:\n",
    "        print(f\"The number of nan value in {column}: {count}\")\n",
    "\n",
    "nan_count_list = [] # Used for step 3\n",
    "for column_order in range(0, data.shape[1]):\n",
    "    nan_count = count_nan(column=columns[column_order], data=data)\n",
    "    nan_count_list.append(nan_count)\n",
    "    print_index(nan_count, columns[column_order])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Drop columns with more than 10% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns with more than 10% missing values: Evaporation, Sunshine, Cloud9am, Cloud3pm\n"
     ]
    }
   ],
   "source": [
    "# Find columns with missing values (nan)\n",
    "missing_value_dict = dict() # Key: Column name; Value: the number of nan\n",
    "for index in range(len(nan_count_list)):\n",
    "    if nan_count_list[index] != 0:\n",
    "        missing_value_dict[columns[index]] = nan_count_list[index]\n",
    "\n",
    "# Calculate percent of missing value for each column\n",
    "percent_nan_dict = dict()\n",
    "for key, value in missing_value_dict.items():\n",
    "    percent_nan_dict[key] = (value / data.shape[0]) * 100\n",
    "    \n",
    "# Find corrensponding columns for columns with more than 10% missing values\n",
    "removed_columns = []\n",
    "for key, value in percent_nan_dict.items():\n",
    "    if(value > 10):\n",
    "        removed_columns.append(key)\n",
    "\n",
    "if removed_columns!= []:\n",
    "    print(\"The columns with more than 10% missing values:\", \", \".join(removed_columns))\n",
    "\n",
    "    data.drop(columns=removed_columns, inplace=True)\n",
    "else:\n",
    "    print(\"There are no columns with more than 10% missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Drop rows with more than 20% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with missing values (nan)\n",
    "missing_values_dict = dict()\n",
    "\n",
    "# Count the total number of missing values for each row\n",
    "for i in range(0, data.shape[0]):\n",
    "    total_missing_value = 0\n",
    "    is_nan_list = np.array(data.iloc[i:i+1,:].isnull())[0]\n",
    "    total_missing_value = np.count_nonzero(is_nan_list)  \n",
    "    missing_values_dict[i] = total_missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no rows with more than 20% missing values\n"
     ]
    }
   ],
   "source": [
    "# Calculate percent of missing value for each row\n",
    "percent_nan_dict = dict()\n",
    "for key, value in missing_values_dict.items():\n",
    "    percent_nan_dict[key] = (value / data.shape[0]) * 100\n",
    "\n",
    "# Find corrensponding rows for rows with more than 20% missing values\n",
    "removed_rows = []\n",
    "for key, value in percent_nan_dict.items():\n",
    "    if(value > 20):\n",
    "        removed_rows.append(key)\n",
    "\n",
    "if removed_rows != []:\n",
    "    print(\"The rows with more than w0% missing values:\", \", \".join(removed_columns))\n",
    "\n",
    "    data.drop(removed_columns, inplace=True)\n",
    "else:\n",
    "    print(\"There are no rows with more than 20% missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Calculate z-score for columns with continuous data and replace outliers by the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and replace outlier\n",
    "def find_outlier_index(col, data):\n",
    "    z_score = (data[col]-data[col].mean()) / data[col].std(ddof=0) # The divisor is (N - ddof), N: the number of elements\n",
    "    z_score_outlier_plus_3 = np.array((z_score > 3))\n",
    "    z_score_outlier_minus_3 = np.array((z_score < -3))\n",
    "    z_score_outlier = np.logical_or(z_score_outlier_plus_3, z_score_outlier_minus_3)\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for index in range(data.shape[0]):\n",
    "        if(z_score_outlier[index] == True):\n",
    "            outlier_indices.append(index)\n",
    "    \n",
    "    return outlier_indices\n",
    "\n",
    "def replace_outlier(col, data):\n",
    "    # Fix outlier by replacing it with avarage value of the column\n",
    "    outlier_indices = find_outlier_index(col, data)\n",
    "    \n",
    "    mean = data[col].mean()\n",
    "    for index in outlier_indices:\n",
    "        data.loc[index, col] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all dropped columns indicated in section 3\n",
    "for column in removed_columns:\n",
    "    continous_columns.remove(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and replace outliers with the mean\n",
    "for column in continous_columns:\n",
    "    replace_outlier(column, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RISK_MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>141556.000000</td>\n",
       "      <td>141871.000000</td>\n",
       "      <td>140787.000000</td>\n",
       "      <td>132923.000000</td>\n",
       "      <td>140845.000000</td>\n",
       "      <td>139563.000000</td>\n",
       "      <td>140419.000000</td>\n",
       "      <td>138583.000000</td>\n",
       "      <td>128179.000000</td>\n",
       "      <td>128212.000000</td>\n",
       "      <td>141289.000000</td>\n",
       "      <td>139467.000000</td>\n",
       "      <td>142193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.187390</td>\n",
       "      <td>23.255333</td>\n",
       "      <td>1.520520</td>\n",
       "      <td>39.492541</td>\n",
       "      <td>13.704389</td>\n",
       "      <td>18.423626</td>\n",
       "      <td>69.046792</td>\n",
       "      <td>51.482606</td>\n",
       "      <td>1017.733322</td>\n",
       "      <td>1015.322035</td>\n",
       "      <td>16.996893</td>\n",
       "      <td>21.711041</td>\n",
       "      <td>1.525971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.399138</td>\n",
       "      <td>7.035087</td>\n",
       "      <td>3.893527</td>\n",
       "      <td>12.631720</td>\n",
       "      <td>8.313620</td>\n",
       "      <td>8.391332</td>\n",
       "      <td>18.724473</td>\n",
       "      <td>20.797772</td>\n",
       "      <td>6.937366</td>\n",
       "      <td>6.896952</td>\n",
       "      <td>6.460597</td>\n",
       "      <td>6.838309</td>\n",
       "      <td>3.899425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>996.400000</td>\n",
       "      <td>994.200000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.600000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1013.000000</td>\n",
       "      <td>1010.500000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.637576</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1017.653758</td>\n",
       "      <td>1015.258204</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.800000</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1022.400000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.200000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1038.900000</td>\n",
       "      <td>1036.300000</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>27.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MinTemp        MaxTemp       Rainfall  WindGustSpeed  \\\n",
       "count  141556.000000  141871.000000  140787.000000  132923.000000   \n",
       "mean       12.187390      23.255333       1.520520      39.492541   \n",
       "std         6.399138       7.035087       3.893527      12.631720   \n",
       "min        -7.000000       1.900000       0.000000       6.000000   \n",
       "25%         7.600000      18.000000       0.000000      31.000000   \n",
       "50%        12.000000      22.700000       0.000000      39.000000   \n",
       "75%        16.800000      28.200000       0.800000      46.000000   \n",
       "max        31.200000      44.500000      27.600000      80.000000   \n",
       "\n",
       "        WindSpeed9am   WindSpeed3pm    Humidity9am    Humidity3pm  \\\n",
       "count  140845.000000  139563.000000  140419.000000  138583.000000   \n",
       "mean       13.704389      18.423626      69.046792      51.482606   \n",
       "std         8.313620       8.391332      18.724473      20.797772   \n",
       "min         0.000000       0.000000      12.000000       0.000000   \n",
       "25%         7.000000      13.000000      57.000000      37.000000   \n",
       "50%        13.000000      18.637576      70.000000      52.000000   \n",
       "75%        19.000000      24.000000      83.000000      66.000000   \n",
       "max        39.000000      44.000000     100.000000     100.000000   \n",
       "\n",
       "         Pressure9am    Pressure3pm        Temp9am        Temp3pm  \\\n",
       "count  128179.000000  128212.000000  141289.000000  139467.000000   \n",
       "mean     1017.733322    1015.322035      16.996893      21.711041   \n",
       "std         6.937366       6.896952       6.460597       6.838309   \n",
       "min       996.400000     994.200000      -2.400000       0.900000   \n",
       "25%      1013.000000    1010.500000      12.300000      16.600000   \n",
       "50%      1017.653758    1015.258204      16.700000      21.200000   \n",
       "75%      1022.400000    1020.000000      21.600000      26.400000   \n",
       "max      1038.900000    1036.300000      36.400000      42.400000   \n",
       "\n",
       "             RISK_MM  \n",
       "count  142193.000000  \n",
       "mean        1.525971  \n",
       "std         3.899425  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.800000  \n",
       "max        27.600000  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Replace all missing values (nan/null) by implementing appropriate algorithms or mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For continuous columns, implement linear regression to model relationship \n",
    "between one column and the 'RISK_MMT' column which has no nan values.\n",
    "\"\"\"\n",
    "def find_nan_indices(column, data):\n",
    "    # List of index of nan values\n",
    "    nan_index = []\n",
    "    \n",
    "    # The number of elements in column\n",
    "    column_len = len(data[column])\n",
    "    \n",
    "    # List of boolean value. If the element is nan, return True; otherwise return False\n",
    "    is_nan_list = np.array(data[column].isna())\n",
    "    \n",
    "    nan_index = np.where(is_nan_list == True)\n",
    "    \n",
    "    return nan_index[0]\n",
    "\n",
    "def fill_missing_value_with_LN(col, data, missing_value_indices):\n",
    "    # Declare one column and another random column\n",
    "    column_name_trained = col\n",
    "    column = data[column_name_trained]\n",
    "    chosen_column = data['RISK_MM']\n",
    "    \n",
    "    # Replacing null values with 0\n",
    "    data[column_name_trained] = data[column_name_trained].fillna(0)\n",
    "    \n",
    "    # # Prepare the data\n",
    "    x = np.c_[chosen_column.values]\n",
    "    y = column.tolist()\n",
    "\n",
    "    # # Fit the model\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(x,y)\n",
    "\n",
    "    # Gain the model parameters\n",
    "    coef = lr.coef_ \n",
    "    intercept = lr.intercept_\n",
    "\n",
    "    # Fill missing value\n",
    "    for index in missing_value_indices:\n",
    "        replaced_value = coef * data.loc[index, 'RISK_MM'] + intercept\n",
    "        data.loc[index, column_name_trained] = round(replaced_value[0],4)\n",
    "        \n",
    "for column in continous_columns:\n",
    "    missing_value_indices = find_nan_indices(column, data)\n",
    "    fill_missing_value_with_LN(col=column, data=data,missing_value_indices=missing_value_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns with nan values: WindGustDir, WindDir9am, WindDir3pm, RainToday\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For nominal columns\n",
    "\"\"\"\n",
    "no_nan_nominal = []\n",
    "nan_nominal = []\n",
    "for column in nominal_columns:\n",
    "    if(data[column].isna().sum() == 0):\n",
    "        no_nan_nominal.append(column)\n",
    "    else:\n",
    "        nan_nominal.append(column)\n",
    "print(\"The columns with nan values:\", \", \".join(nan_nominal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fill missing values in WindGustDir, WindDir9am, WindDir3pm\n",
    "columns by applying random direction\n",
    "\"\"\"\n",
    "def fill_missing_values_random(column, data):\n",
    "    # Find indices of na values\n",
    "    na_indices = find_nan_indices(column, data)\n",
    "    \n",
    "    # Find all unique directions\n",
    "    unique_direction = list(set(data[column]))\n",
    "    # Drop na element out of unique direction list\n",
    "    unique_direction.remove(np.nan)\n",
    "    \n",
    "    for index in na_indices:\n",
    "        random_number = random.randint(0, len(unique_direction)-1)\n",
    "        random_direction = unique_direction[random_number]\n",
    "        data.loc[index, column] = random_direction\n",
    "\n",
    "for na_column in nan_nominal[0:-1]:\n",
    "    fill_missing_values_random(na_column, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fill missing values in \n",
    "column by applying Naive Bayes \n",
    "\"\"\"\n",
    "def delete_elements(data, indices):\n",
    "    return list(np.delete(data, indices))\n",
    "\n",
    "def encode_data(data, encode_is_key = True):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoded_data = encoder.fit_transform(data)\n",
    "    reversed_data = encoder.inverse_transform(encoded_data)\n",
    "    \n",
    "    if(encode_is_key):\n",
    "        dict_data = dict(zip(encoded_data, reversed_data))\n",
    "    else:\n",
    "        dict_data = dict(zip(reversed_data, encoded_data))\n",
    "        \n",
    "    return encoded_data, dict_data\n",
    "    \n",
    "def fill_missing_values_NB(column, data):\n",
    "    # Find indices of na values\n",
    "    na_indices = find_nan_indices(column, data)\n",
    "    \n",
    "    # Choose 'WindDir3pm' and 'RainTomorrow' columns \n",
    "    data_WindDir3pm = list(data['WindDir3pm'])\n",
    "    data_RainTomorrow = list(data['RainTomorrow'])\n",
    "    \n",
    "    # The given column need to be filled\n",
    "    data_column = list(data[column])\n",
    "    \n",
    "    all_data = [data_WindDir3pm, data_RainTomorrow, data_column ]\n",
    "    # Remove na value from data_column\n",
    "    # Remove values in 'WindDir3pm' column corresponding na value\n",
    "    # Remove values in 'RainTomorrow' column corresponding na value\n",
    "    data_column = delete_elements(data_column, na_indices)\n",
    "    data_WindDir3pm = delete_elements(data_WindDir3pm, na_indices)\n",
    "    data_RainTomorrow = delete_elements(data_RainTomorrow, na_indices)\n",
    "    \n",
    "    # Label\n",
    "    encoded_column, dict_column = encode_data(data_column, encode_is_key=True)\n",
    "    \n",
    "    # Features\n",
    "    encoded_WindDir3pm, dict_WindDir3pm = encode_data(data_WindDir3pm, encode_is_key=False)\n",
    "    encoded_RainTomorrow, dict_RainTomorrow = encode_data(data_RainTomorrow, encode_is_key=False)\n",
    "    # Create features by combining WindDir3pm and RainTomorrow\n",
    "    features= list(zip(encoded_RainTomorrow, encoded_WindDir3pm))\n",
    "    \n",
    "    #Create a Gaussian Classifier\n",
    "    model = GaussianNB()\n",
    "    \n",
    "    # Train the model using the training sets\n",
    "    model.fit(features,encoded_column)\n",
    "    \n",
    "    for index in na_indices:\n",
    "        rain_tomorrow = data.loc[index, 'RainTomorrow']\n",
    "        wind_dir = data.loc[index, 'WindDir3pm']\n",
    "        # Predict the value\n",
    "        predicted_value = model.predict([[dict_RainTomorrow[rain_tomorrow],dict_WindDir3pm[wind_dir]]])\n",
    "        # Fill missing values with predicted values\n",
    "        data.loc[index, column] = dict_column[predicted_value[0]]\n",
    "        \n",
    "fill_missing_values_NB('RainToday', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "# data.to_csv(\"data/cleaned_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
